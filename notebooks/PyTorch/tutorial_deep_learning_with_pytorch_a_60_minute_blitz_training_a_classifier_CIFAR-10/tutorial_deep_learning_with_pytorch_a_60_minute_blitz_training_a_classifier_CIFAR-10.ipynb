{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import logging\n",
    "from logging import getLogger\n",
    "from logging import StreamHandler\n",
    "from logging import INFO, WARNING\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "handler = StreamHandler()\n",
    "handler.setLevel(INFO)\n",
    "logger.setLevel(INFO)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = \"train\"\n",
    "VAL = \"val\"\n",
    "TEST = \"test\"\n",
    "PHASES = [TRAIN, VAL]\n",
    "\n",
    "SAVE_PATH = os.path.join(os.getcwd(), \"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_formatted_time(elapsed_time, msg=\"\"):\n",
    "    minutes, seconds = map(int, divmod(elapsed_time, 60))\n",
    "    print(\"Elapsed time - {0}: {1}min {2}s\".format(msg, minutes, seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model_name=\"\"):\n",
    "    model_path = os.path.join(SAVE_PATH, model_name)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "def load_model(model_name):\n",
    "    model = Net().to(device)\n",
    "    model_path = os.path.join(SAVE_PATH, model_name)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "test_batch_size = 256\n",
    "\n",
    "# default\n",
    "params = {\n",
    "    \"batch_size\": 512,\n",
    "    \"epochs\": 10,\n",
    "    \"lr\": 0.001,\n",
    "    \"momentum\": 0.9,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_datasets(data_transforms):\n",
    "    \"\"\"画像前処理変更したら呼ぶ\"\"\"\n",
    "    image_datasets = {phase: torchvision.datasets.CIFAR10(root=\"../../data\",\n",
    "                                                                                                       train=phase is \"train\",\n",
    "                                                                                                       download=True,\n",
    "                                                                                                       transform=data_transforms[phase])\n",
    "                                      for phase in PHASES}\n",
    "    dataset_sizes = {phase: len(image_datasets[phase]) for phase in PHASES}\n",
    "    return image_datasets, dataset_sizes\n",
    "\n",
    "def init_dataloaders(batch_size, image_datasets):\n",
    "    \"\"\"バッチサイズ変更したら呼ぶ\"\"\"\n",
    "    return {phase: torch.utils.data.DataLoader(image_datasets[phase],\n",
    "                                                                               batch_size=batch_size,\n",
    "                                                                               shuffle=True,\n",
    "                                                                               num_workers=4)\n",
    "                 for phase in [\"train\", \"val\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets, dataset_sizes = init_datasets(data_transforms)\n",
    "dataloaders = init_dataloaders(params[\"batch_size\"], image_datasets)\n",
    "\n",
    "classes = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ship   cat plane horse plane truck  frog   dog truck  bird  deer  deer  frog   dog truck horse   dog  deer  ship  deer  frog   cat  deer   dog  bird   cat  deer truck   car   dog   dog   car   dog   cat  deer  ship truck   cat  ship   cat truck  bird   cat   dog horse  ship truck  deer truck  ship plane plane   dog  bird  frog truck  bird truck   dog truck  frog plane  deer   cat  frog truck  frog  ship horse  bird plane  bird  deer horse  ship horse truck   car truck   car truck horse  frog   cat  bird plane truck horse   dog  deer   dog   cat   dog  ship horse   dog truck horse   car plane  bird  ship   dog  ship  frog  bird plane horse plane  deer  deer plane  bird plane  deer  deer horse   car truck plane  bird  bird horse  bird  bird truck   car truck truck plane  deer  ship   dog  frog plane  bird truck   dog   dog   car truck  bird  deer  bird plane  frog horse   cat   car   dog horse truck  deer  frog  ship  frog  bird  ship   cat   car   dog  frog  frog horse   cat horse   dog plane plane   dog   car   car   cat horse  ship  frog  frog truck truck horse plane   dog  deer   dog   dog  ship   car   cat   dog   cat   car  ship  bird   car truck  frog   cat  frog horse  bird truck horse  bird   cat plane  bird   dog   car  ship plane   cat   car   cat  frog  frog horse  bird  bird truck plane horse  deer  frog   cat  frog horse   cat   cat  bird  ship truck  bird truck   car   car   dog truck   dog   car   car  frog   cat   car  bird  ship truck   cat  ship  deer   cat   dog  bird  bird  ship truck   dog horse   dog  deer horse  ship  deer horse   cat horse horse   dog  ship  deer  bird plane   car  bird   cat   dog  bird  frog   car plane  bird   car  ship  deer plane plane  deer  ship plane  ship  deer  frog  ship  ship   dog  frog  ship   cat   car   dog   car  ship   dog  frog  frog   dog  ship  bird horse plane   dog truck  deer truck  frog  ship   cat   cat   dog  frog   dog  bird  frog  bird plane  frog  deer   car  bird  deer   cat   dog   car truck truck truck  ship   dog   dog  deer   car  deer truck  deer  ship horse   cat plane   cat plane  deer plane   cat  deer  frog horse truck truck plane  frog  frog horse  deer  deer  deer plane   dog   car   dog  deer  ship horse  deer  bird   cat   dog  deer plane   cat  frog  bird plane  bird truck horse truck  ship  frog plane plane   cat  ship plane truck  frog  frog  bird  deer   car  ship  frog  ship  frog truck  ship plane plane horse  bird   dog horse  deer  frog   car truck   dog plane  frog plane horse  frog plane   dog truck   car  ship   cat truck plane   car  ship  frog   cat plane  frog   cat plane truck truck truck   dog horse horse  frog  ship horse  ship plane   cat plane truck truck   dog plane  ship  deer  deer   dog  bird truck  bird   car plane plane  frog  bird horse   cat horse   car  ship  bird   dog  bird   car horse   dog horse horse   car plane  bird horse   dog   car  frog  ship  bird  bird   cat plane  deer   car  ship horse   car  frog plane  frog   cat  ship truck horse horse  frog   cat  deer plane  deer plane   dog   dog  frog\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-818:\n",
      "Process Process-817:\n",
      "Traceback (most recent call last):\n",
      "Process Process-819:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-820:\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/shitaked/.local/share/virtualenvs/ml-sandbox-mZj7E2fu/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shitaked/.local/share/virtualenvs/ml-sandbox-mZj7E2fu/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/shitaked/.local/share/virtualenvs/ml-sandbox-mZj7E2fu/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/shitaked/.local/share/virtualenvs/ml-sandbox-mZj7E2fu/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/shitaked/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(dataloaders[TRAIN])\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(\" \".join(\"%5s\" % classes[labels[j]] for j in range(params[\"batch_size\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from net import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net,  self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,  16,  5)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(2,  2)\n",
    "        self.conv2 = nn.Conv2d(16,  16,  5)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5,  120)\n",
    "        self.fc2 = nn.Linear(120,  84)\n",
    "        self.fc3 = nn.Linear(84,  10)\n",
    "\n",
    "    def forward(self,  x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # 32x32x3 ->  28x28x6 ->14x14x6\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  #  ->10x10x16 -> 5x5x16\n",
    "        x = x.view(-1,  16 * 5 * 5)  # -> 400\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler, params):\n",
    "    since = time.time()\n",
    "    \n",
    "    epochs = params[\"epochs\"]\n",
    "\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = dict()\n",
    "        epoch_acc = dict()\n",
    "        \n",
    "        for phase in PHASES:\n",
    "            if phase == TRAIN:\n",
    "                is_train = True\n",
    "                scheduler.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                is_train = False\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for batch_idx, (inputs, labels) in enumerate(dataloaders[phase], 0):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(is_train):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if is_train:\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss[phase] = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc[phase] = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            if phase == VAL and epoch_acc[phase] > best_acc:\n",
    "                best_acc = epoch_acc[phase]\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print(\"Epoch {}/{}\\tTrain Loss: {:.4f} Acc: {:.4f}\\tVal Loss: {:.4f} Acc: {:.4f}\".format(\n",
    "            epoch,\n",
    "            epochs - 1,\n",
    "            epoch_loss[TRAIN],\n",
    "            epoch_acc[TRAIN],\n",
    "            epoch_loss[VAL],\n",
    "            epoch_acc[VAL]\n",
    "        ))\n",
    "\n",
    "    print()\n",
    "    print(\"Best val Acc: {:4f}\".format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_weights)\n",
    "    \n",
    "    print()\n",
    "    display_formatted_time(time.time() - since)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc():\n",
    "    \"\"\"ラベルごとの精度を算出\"\"\"\n",
    "    class_correct = [0. for i in range(len(classes))]\n",
    "    class_total = [0. for i in range(len(classes))]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders[VAL]:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    for i in range(10):\n",
    "        print(\"Accuracy of\\t%5s:\\t%2d %%\" % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 0/49\tTrain Loss: 1.6685 Acc: 0.3775\tVal Loss: 1.4566 Acc: 0.4660\n",
      "Epoch 1/49\tTrain Loss: 1.3080 Acc: 0.5230\tVal Loss: 1.2304 Acc: 0.5575\n",
      "Epoch 2/49\tTrain Loss: 1.1771 Acc: 0.5756\tVal Loss: 1.1965 Acc: 0.5668\n",
      "Epoch 3/49\tTrain Loss: 1.0930 Acc: 0.6083\tVal Loss: 1.0799 Acc: 0.6154\n",
      "Epoch 4/49\tTrain Loss: 1.0445 Acc: 0.6260\tVal Loss: 1.0697 Acc: 0.6119\n",
      "Epoch 5/49\tTrain Loss: 1.0072 Acc: 0.6403\tVal Loss: 1.0287 Acc: 0.6319\n",
      "Epoch 6/49\tTrain Loss: 0.9812 Acc: 0.6509\tVal Loss: 1.0045 Acc: 0.6429\n",
      "Epoch 7/49\tTrain Loss: 0.9601 Acc: 0.6592\tVal Loss: 0.9874 Acc: 0.6481\n",
      "Epoch 8/49\tTrain Loss: 0.9481 Acc: 0.6644\tVal Loss: 0.9764 Acc: 0.6565\n",
      "Epoch 9/49\tTrain Loss: 0.9391 Acc: 0.6663\tVal Loss: 0.9735 Acc: 0.6577\n",
      "Epoch 10/49\tTrain Loss: 0.9383 Acc: 0.6663\tVal Loss: 0.9734 Acc: 0.6561\n",
      "Epoch 11/49\tTrain Loss: 0.9382 Acc: 0.6660\tVal Loss: 0.9715 Acc: 0.6583\n",
      "Epoch 12/49\tTrain Loss: 0.9408 Acc: 0.6667\tVal Loss: 0.9695 Acc: 0.6570\n",
      "Epoch 13/49\tTrain Loss: 0.9411 Acc: 0.6662\tVal Loss: 0.9690 Acc: 0.6581\n",
      "Epoch 14/49\tTrain Loss: 0.9398 Acc: 0.6651\tVal Loss: 0.9812 Acc: 0.6537\n",
      "Epoch 15/49\tTrain Loss: 0.9377 Acc: 0.6667\tVal Loss: 0.9837 Acc: 0.6567\n",
      "Epoch 16/49\tTrain Loss: 0.9298 Acc: 0.6677\tVal Loss: 1.0191 Acc: 0.6412\n",
      "Epoch 17/49\tTrain Loss: 0.9219 Acc: 0.6712\tVal Loss: 1.0107 Acc: 0.6493\n",
      "Epoch 18/49\tTrain Loss: 0.9079 Acc: 0.6760\tVal Loss: 0.9592 Acc: 0.6584\n",
      "Epoch 19/49\tTrain Loss: 0.8856 Acc: 0.6858\tVal Loss: 0.9124 Acc: 0.6790\n",
      "Epoch 20/49\tTrain Loss: 0.8641 Acc: 0.6932\tVal Loss: 0.9435 Acc: 0.6663\n",
      "Epoch 21/49\tTrain Loss: 0.8512 Acc: 0.6974\tVal Loss: 0.9110 Acc: 0.6734\n",
      "Epoch 22/49\tTrain Loss: 0.8275 Acc: 0.7060\tVal Loss: 0.9028 Acc: 0.6796\n",
      "Epoch 23/49\tTrain Loss: 0.8053 Acc: 0.7143\tVal Loss: 0.8702 Acc: 0.6903\n",
      "Epoch 24/49\tTrain Loss: 0.7875 Acc: 0.7204\tVal Loss: 0.8775 Acc: 0.6842\n",
      "Epoch 25/49\tTrain Loss: 0.7727 Acc: 0.7281\tVal Loss: 0.8381 Acc: 0.7020\n",
      "Epoch 26/49\tTrain Loss: 0.7502 Acc: 0.7366\tVal Loss: 0.8577 Acc: 0.6972\n",
      "Epoch 27/49\tTrain Loss: 0.7361 Acc: 0.7405\tVal Loss: 0.8357 Acc: 0.7070\n",
      "Epoch 28/49\tTrain Loss: 0.7298 Acc: 0.7433\tVal Loss: 0.8261 Acc: 0.7050\n",
      "Epoch 29/49\tTrain Loss: 0.7213 Acc: 0.7471\tVal Loss: 0.8228 Acc: 0.7072\n",
      "Epoch 30/49\tTrain Loss: 0.7183 Acc: 0.7485\tVal Loss: 0.8224 Acc: 0.7071\n",
      "Epoch 31/49\tTrain Loss: 0.7196 Acc: 0.7476\tVal Loss: 0.8207 Acc: 0.7088\n",
      "Epoch 32/49\tTrain Loss: 0.7234 Acc: 0.7472\tVal Loss: 0.8207 Acc: 0.7078\n",
      "Epoch 33/49\tTrain Loss: 0.7290 Acc: 0.7438\tVal Loss: 0.8214 Acc: 0.7074\n",
      "Epoch 34/49\tTrain Loss: 0.7341 Acc: 0.7415\tVal Loss: 0.8457 Acc: 0.7011\n",
      "Epoch 35/49\tTrain Loss: 0.7367 Acc: 0.7411\tVal Loss: 0.8341 Acc: 0.7028\n",
      "Epoch 36/49\tTrain Loss: 0.7419 Acc: 0.7380\tVal Loss: 0.8404 Acc: 0.7040\n",
      "Epoch 37/49\tTrain Loss: 0.7454 Acc: 0.7373\tVal Loss: 0.8656 Acc: 0.6959\n",
      "Epoch 38/49\tTrain Loss: 0.7389 Acc: 0.7396\tVal Loss: 0.8542 Acc: 0.6928\n",
      "Epoch 39/49\tTrain Loss: 0.7271 Acc: 0.7428\tVal Loss: 0.8858 Acc: 0.6912\n",
      "Epoch 40/49\tTrain Loss: 0.7196 Acc: 0.7450\tVal Loss: 0.8331 Acc: 0.7043\n",
      "Epoch 41/49\tTrain Loss: 0.7129 Acc: 0.7477\tVal Loss: 0.8095 Acc: 0.7181\n",
      "Epoch 42/49\tTrain Loss: 0.6900 Acc: 0.7570\tVal Loss: 0.8229 Acc: 0.7096\n",
      "Epoch 43/49\tTrain Loss: 0.6739 Acc: 0.7648\tVal Loss: 0.8351 Acc: 0.7093\n",
      "Epoch 44/49\tTrain Loss: 0.6570 Acc: 0.7695\tVal Loss: 0.8106 Acc: 0.7165\n",
      "Epoch 45/49\tTrain Loss: 0.6387 Acc: 0.7756\tVal Loss: 0.8117 Acc: 0.7131\n",
      "Epoch 46/49\tTrain Loss: 0.6283 Acc: 0.7794\tVal Loss: 0.7893 Acc: 0.7216\n",
      "Epoch 47/49\tTrain Loss: 0.6130 Acc: 0.7846\tVal Loss: 0.7734 Acc: 0.7312\n",
      "Epoch 48/49\tTrain Loss: 0.6038 Acc: 0.7889\tVal Loss: 0.7712 Acc: 0.7296\n",
      "Epoch 49/49\tTrain Loss: 0.5934 Acc: 0.7926\tVal Loss: 0.7680 Acc: 0.7316\n",
      "\n",
      "Best val Acc: 0.731600\n",
      "\n",
      "Elapsed time - : 2min 9s\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"batch_size\": 512,\n",
    "    \"epochs\": 50,\n",
    "    \"lr\": 0.001,\n",
    "    \"momentum\": 0.9,\n",
    "}\n",
    "\n",
    "image_datasets, dataset_sizes = init_datasets(data_transforms=data_transforms)\n",
    "dataloaders = init_dataloaders(params[\"batch_size\"], image_datasets=image_datasets)\n",
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(),\n",
    "#                                          lr=params[\"lr\"],\n",
    "#                                          momentum=params[\"momentum\"])\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                                            lr=params[\"lr\"])\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer=optimizer,\n",
    "                                                                              T_max=10,  # Maximum number of iterations\n",
    "                                                                              eta_min=0,  # 最小学習率\n",
    "                                                                              last_epoch=-1)  # The index of last epoch\n",
    "\n",
    "model = train(model, criterion, optimizer, scheduler, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of\tplane:\t76 %\n",
      "Accuracy of\t  car:\t84 %\n",
      "Accuracy of\t bird:\t60 %\n",
      "Accuracy of\t  cat:\t51 %\n",
      "Accuracy of\t deer:\t70 %\n",
      "Accuracy of\t  dog:\t61 %\n",
      "Accuracy of\t frog:\t82 %\n",
      "Accuracy of\thorse:\t77 %\n",
      "Accuracy of\t ship:\t83 %\n",
      "Accuracy of\ttruck:\t82 %\n"
     ]
    }
   ],
   "source": [
    "calc_acc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(\"original_Adam_epoch50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"original_SGD_epoch50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99[624/50000 (20%)]\tTrain Loss: 1.5328 Acc: 0.4385\tVal Loss: 1.2943 Acc: 0.5318\n",
      "Epoch 1/99[624/50000 (20%)]\tTrain Loss: 1.2106 Acc: 0.5621\tVal Loss: 1.2094 Acc: 0.5717\n",
      "Epoch 2/99[624/50000 (20%)]\tTrain Loss: 1.0949 Acc: 0.6089\tVal Loss: 1.0720 Acc: 0.6148\n",
      "Epoch 3/99[624/50000 (20%)]\tTrain Loss: 1.0265 Acc: 0.6341\tVal Loss: 1.0469 Acc: 0.6311\n",
      "Epoch 4/99[624/50000 (20%)]\tTrain Loss: 0.9781 Acc: 0.6531\tVal Loss: 1.0281 Acc: 0.6424\n",
      "Epoch 5/99[624/50000 (20%)]\tTrain Loss: 0.9367 Acc: 0.6682\tVal Loss: 0.9452 Acc: 0.6680\n",
      "Epoch 6/99[624/50000 (20%)]\tTrain Loss: 0.8969 Acc: 0.6809\tVal Loss: 0.9325 Acc: 0.6695\n",
      "Epoch 7/99[624/50000 (20%)]\tTrain Loss: 0.8744 Acc: 0.6907\tVal Loss: 0.9145 Acc: 0.6821\n",
      "Epoch 8/99[624/50000 (20%)]\tTrain Loss: 0.8613 Acc: 0.6944\tVal Loss: 0.9054 Acc: 0.6823\n",
      "Epoch 9/99[624/50000 (20%)]\tTrain Loss: 0.8455 Acc: 0.7003\tVal Loss: 0.8968 Acc: 0.6883\n",
      "Epoch 10/99[624/50000 (20%)]\tTrain Loss: 0.8446 Acc: 0.7013\tVal Loss: 0.8966 Acc: 0.6886\n",
      "Epoch 11/99[624/50000 (20%)]\tTrain Loss: 0.8442 Acc: 0.7023\tVal Loss: 0.8956 Acc: 0.6904\n",
      "Epoch 12/99[624/50000 (20%)]\tTrain Loss: 0.8463 Acc: 0.6988\tVal Loss: 0.8957 Acc: 0.6876\n",
      "Epoch 13/99[624/50000 (20%)]\tTrain Loss: 0.8498 Acc: 0.6978\tVal Loss: 0.9008 Acc: 0.6864\n",
      "Epoch 14/99[624/50000 (20%)]\tTrain Loss: 0.8554 Acc: 0.6969\tVal Loss: 0.9005 Acc: 0.6837\n",
      "Epoch 15/99[624/50000 (20%)]\tTrain Loss: 0.8509 Acc: 0.6986\tVal Loss: 0.9043 Acc: 0.6841\n",
      "Epoch 16/99[624/50000 (20%)]\tTrain Loss: 0.8473 Acc: 0.7000\tVal Loss: 0.9260 Acc: 0.6737\n",
      "Epoch 17/99[624/50000 (20%)]\tTrain Loss: 0.8352 Acc: 0.7042\tVal Loss: 0.8983 Acc: 0.6839\n",
      "Epoch 18/99[624/50000 (20%)]\tTrain Loss: 0.8258 Acc: 0.7071\tVal Loss: 0.8983 Acc: 0.6795\n",
      "Epoch 19/99[624/50000 (20%)]\tTrain Loss: 0.8116 Acc: 0.7140\tVal Loss: 0.8890 Acc: 0.6871\n",
      "Epoch 20/99[624/50000 (20%)]\tTrain Loss: 0.7904 Acc: 0.7205\tVal Loss: 0.8867 Acc: 0.6888\n",
      "Epoch 21/99[624/50000 (20%)]\tTrain Loss: 0.7632 Acc: 0.7294\tVal Loss: 0.8610 Acc: 0.6971\n",
      "Epoch 22/99[624/50000 (20%)]\tTrain Loss: 0.7371 Acc: 0.7424\tVal Loss: 0.8421 Acc: 0.7073\n",
      "Epoch 23/99[624/50000 (20%)]\tTrain Loss: 0.7198 Acc: 0.7457\tVal Loss: 0.8601 Acc: 0.7030\n",
      "Epoch 24/99[624/50000 (20%)]\tTrain Loss: 0.6962 Acc: 0.7535\tVal Loss: 0.8547 Acc: 0.7077\n",
      "Epoch 25/99[624/50000 (20%)]\tTrain Loss: 0.6689 Acc: 0.7645\tVal Loss: 0.7974 Acc: 0.7231\n",
      "Epoch 26/99[624/50000 (20%)]\tTrain Loss: 0.6485 Acc: 0.7716\tVal Loss: 0.7879 Acc: 0.7280\n",
      "Epoch 27/99[624/50000 (20%)]\tTrain Loss: 0.6309 Acc: 0.7799\tVal Loss: 0.7821 Acc: 0.7328\n",
      "Epoch 28/99[624/50000 (20%)]\tTrain Loss: 0.6174 Acc: 0.7842\tVal Loss: 0.7713 Acc: 0.7325\n",
      "Epoch 29/99[624/50000 (20%)]\tTrain Loss: 0.6106 Acc: 0.7863\tVal Loss: 0.7697 Acc: 0.7340\n",
      "Epoch 30/99[624/50000 (20%)]\tTrain Loss: 0.6078 Acc: 0.7881\tVal Loss: 0.7718 Acc: 0.7356\n",
      "Epoch 31/99[624/50000 (20%)]\tTrain Loss: 0.6100 Acc: 0.7859\tVal Loss: 0.7700 Acc: 0.7338\n",
      "Epoch 32/99[624/50000 (20%)]\tTrain Loss: 0.6145 Acc: 0.7855\tVal Loss: 0.7748 Acc: 0.7329\n",
      "Epoch 33/99[624/50000 (20%)]\tTrain Loss: 0.6226 Acc: 0.7818\tVal Loss: 0.7791 Acc: 0.7319\n",
      "Epoch 34/99[624/50000 (20%)]\tTrain Loss: 0.6308 Acc: 0.7771\tVal Loss: 0.7962 Acc: 0.7285\n",
      "Epoch 35/99[624/50000 (20%)]\tTrain Loss: 0.6415 Acc: 0.7734\tVal Loss: 0.7983 Acc: 0.7243\n",
      "Epoch 36/99[624/50000 (20%)]\tTrain Loss: 0.6504 Acc: 0.7697\tVal Loss: 0.8197 Acc: 0.7175\n",
      "Epoch 37/99[624/50000 (20%)]\tTrain Loss: 0.6615 Acc: 0.7660\tVal Loss: 0.8379 Acc: 0.7180\n",
      "Epoch 38/99[624/50000 (20%)]\tTrain Loss: 0.6565 Acc: 0.7670\tVal Loss: 0.8155 Acc: 0.7244\n",
      "Epoch 39/99[624/50000 (20%)]\tTrain Loss: 0.6545 Acc: 0.7688\tVal Loss: 0.8456 Acc: 0.7076\n",
      "Epoch 40/99[624/50000 (20%)]\tTrain Loss: 0.6471 Acc: 0.7714\tVal Loss: 0.8665 Acc: 0.7069\n",
      "Epoch 41/99[624/50000 (20%)]\tTrain Loss: 0.6376 Acc: 0.7751\tVal Loss: 0.8581 Acc: 0.7139\n",
      "Epoch 42/99[624/50000 (20%)]\tTrain Loss: 0.6136 Acc: 0.7835\tVal Loss: 0.8110 Acc: 0.7248\n",
      "Epoch 43/99[624/50000 (20%)]\tTrain Loss: 0.6011 Acc: 0.7884\tVal Loss: 0.8028 Acc: 0.7276\n",
      "Epoch 44/99[624/50000 (20%)]\tTrain Loss: 0.5755 Acc: 0.7984\tVal Loss: 0.7997 Acc: 0.7260\n",
      "Epoch 45/99[624/50000 (20%)]\tTrain Loss: 0.5569 Acc: 0.8040\tVal Loss: 0.7890 Acc: 0.7344\n",
      "Epoch 46/99[624/50000 (20%)]\tTrain Loss: 0.5369 Acc: 0.8131\tVal Loss: 0.7730 Acc: 0.7415\n",
      "Epoch 47/99[624/50000 (20%)]\tTrain Loss: 0.5209 Acc: 0.8176\tVal Loss: 0.7734 Acc: 0.7423\n",
      "Epoch 48/99[624/50000 (20%)]\tTrain Loss: 0.5109 Acc: 0.8223\tVal Loss: 0.7671 Acc: 0.7416\n",
      "Epoch 49/99[624/50000 (20%)]\tTrain Loss: 0.4978 Acc: 0.8268\tVal Loss: 0.7646 Acc: 0.7446\n",
      "Epoch 50/99[624/50000 (20%)]\tTrain Loss: 0.4977 Acc: 0.8272\tVal Loss: 0.7639 Acc: 0.7441\n",
      "Epoch 51/99[624/50000 (20%)]\tTrain Loss: 0.4974 Acc: 0.8283\tVal Loss: 0.7643 Acc: 0.7454\n",
      "Epoch 52/99[624/50000 (20%)]\tTrain Loss: 0.5033 Acc: 0.8243\tVal Loss: 0.7731 Acc: 0.7431\n",
      "Epoch 53/99[624/50000 (20%)]\tTrain Loss: 0.5135 Acc: 0.8193\tVal Loss: 0.7947 Acc: 0.7380\n",
      "Epoch 54/99[624/50000 (20%)]\tTrain Loss: 0.5216 Acc: 0.8154\tVal Loss: 0.7922 Acc: 0.7389\n",
      "Epoch 55/99[624/50000 (20%)]\tTrain Loss: 0.5370 Acc: 0.8117\tVal Loss: 0.7970 Acc: 0.7317\n",
      "Epoch 56/99[624/50000 (20%)]\tTrain Loss: 0.5451 Acc: 0.8071\tVal Loss: 0.8203 Acc: 0.7283\n",
      "Epoch 57/99[624/50000 (20%)]\tTrain Loss: 0.5537 Acc: 0.8041\tVal Loss: 0.8275 Acc: 0.7285\n",
      "Epoch 58/99[624/50000 (20%)]\tTrain Loss: 0.5619 Acc: 0.8040\tVal Loss: 0.8207 Acc: 0.7206\n",
      "Epoch 59/99[624/50000 (20%)]\tTrain Loss: 0.5688 Acc: 0.8003\tVal Loss: 0.8086 Acc: 0.7301\n",
      "Epoch 60/99[624/50000 (20%)]\tTrain Loss: 0.5578 Acc: 0.8025\tVal Loss: 0.8535 Acc: 0.7216\n",
      "Epoch 61/99[624/50000 (20%)]\tTrain Loss: 0.5532 Acc: 0.8048\tVal Loss: 0.8025 Acc: 0.7330\n",
      "Epoch 62/99[624/50000 (20%)]\tTrain Loss: 0.5363 Acc: 0.8094\tVal Loss: 0.8058 Acc: 0.7341\n",
      "Epoch 63/99[624/50000 (20%)]\tTrain Loss: 0.5198 Acc: 0.8165\tVal Loss: 0.8281 Acc: 0.7259\n",
      "Epoch 64/99[624/50000 (20%)]\tTrain Loss: 0.5062 Acc: 0.8211\tVal Loss: 0.8283 Acc: 0.7313\n",
      "Epoch 65/99[624/50000 (20%)]\tTrain Loss: 0.4814 Acc: 0.8322\tVal Loss: 0.7964 Acc: 0.7400\n",
      "Epoch 66/99[624/50000 (20%)]\tTrain Loss: 0.4602 Acc: 0.8415\tVal Loss: 0.7963 Acc: 0.7422\n",
      "Epoch 67/99[624/50000 (20%)]\tTrain Loss: 0.4481 Acc: 0.8453\tVal Loss: 0.7956 Acc: 0.7441\n",
      "Epoch 68/99[624/50000 (20%)]\tTrain Loss: 0.4311 Acc: 0.8520\tVal Loss: 0.7874 Acc: 0.7456\n",
      "Epoch 69/99[624/50000 (20%)]\tTrain Loss: 0.4266 Acc: 0.8543\tVal Loss: 0.7864 Acc: 0.7463\n",
      "Epoch 70/99[624/50000 (20%)]\tTrain Loss: 0.4261 Acc: 0.8540\tVal Loss: 0.7860 Acc: 0.7456\n",
      "Epoch 71/99[624/50000 (20%)]\tTrain Loss: 0.4240 Acc: 0.8551\tVal Loss: 0.7877 Acc: 0.7474\n",
      "Epoch 72/99[624/50000 (20%)]\tTrain Loss: 0.4316 Acc: 0.8521\tVal Loss: 0.7887 Acc: 0.7464\n",
      "Epoch 73/99[624/50000 (20%)]\tTrain Loss: 0.4402 Acc: 0.8475\tVal Loss: 0.7988 Acc: 0.7434\n",
      "Epoch 74/99[624/50000 (20%)]\tTrain Loss: 0.4515 Acc: 0.8421\tVal Loss: 0.8080 Acc: 0.7416\n",
      "Epoch 75/99[624/50000 (20%)]\tTrain Loss: 0.4678 Acc: 0.8349\tVal Loss: 0.8206 Acc: 0.7369\n",
      "Epoch 76/99[624/50000 (20%)]\tTrain Loss: 0.4780 Acc: 0.8325\tVal Loss: 0.8574 Acc: 0.7250\n",
      "Epoch 77/99[624/50000 (20%)]\tTrain Loss: 0.4981 Acc: 0.8236\tVal Loss: 0.8458 Acc: 0.7294\n",
      "Epoch 78/99[624/50000 (20%)]\tTrain Loss: 0.5028 Acc: 0.8213\tVal Loss: 0.8497 Acc: 0.7266\n",
      "Epoch 79/99[624/50000 (20%)]\tTrain Loss: 0.5055 Acc: 0.8222\tVal Loss: 0.8432 Acc: 0.7288\n",
      "Epoch 80/99[624/50000 (20%)]\tTrain Loss: 0.5029 Acc: 0.8216\tVal Loss: 0.8467 Acc: 0.7258\n",
      "Epoch 81/99[624/50000 (20%)]\tTrain Loss: 0.4893 Acc: 0.8262\tVal Loss: 0.8530 Acc: 0.7348\n",
      "Epoch 82/99[624/50000 (20%)]\tTrain Loss: 0.4867 Acc: 0.8275\tVal Loss: 0.8616 Acc: 0.7241\n",
      "Epoch 83/99[624/50000 (20%)]\tTrain Loss: 0.4635 Acc: 0.8347\tVal Loss: 0.8411 Acc: 0.7315\n",
      "Epoch 84/99[624/50000 (20%)]\tTrain Loss: 0.4395 Acc: 0.8463\tVal Loss: 0.8135 Acc: 0.7401\n",
      "Epoch 85/99[624/50000 (20%)]\tTrain Loss: 0.4210 Acc: 0.8537\tVal Loss: 0.8255 Acc: 0.7434\n",
      "Epoch 86/99[624/50000 (20%)]\tTrain Loss: 0.4049 Acc: 0.8596\tVal Loss: 0.8452 Acc: 0.7421\n",
      "Epoch 87/99[624/50000 (20%)]\tTrain Loss: 0.3898 Acc: 0.8656\tVal Loss: 0.8254 Acc: 0.7484\n",
      "Epoch 88/99[624/50000 (20%)]\tTrain Loss: 0.3759 Acc: 0.8718\tVal Loss: 0.8277 Acc: 0.7487\n",
      "Epoch 89/99[624/50000 (20%)]\tTrain Loss: 0.3673 Acc: 0.8747\tVal Loss: 0.8256 Acc: 0.7489\n",
      "Epoch 90/99[624/50000 (20%)]\tTrain Loss: 0.3664 Acc: 0.8744\tVal Loss: 0.8238 Acc: 0.7470\n",
      "Epoch 91/99[624/50000 (20%)]\tTrain Loss: 0.3646 Acc: 0.8774\tVal Loss: 0.8277 Acc: 0.7466\n",
      "Epoch 92/99[624/50000 (20%)]\tTrain Loss: 0.3720 Acc: 0.8722\tVal Loss: 0.8316 Acc: 0.7464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/99[624/50000 (20%)]\tTrain Loss: 0.3795 Acc: 0.8705\tVal Loss: 0.8431 Acc: 0.7445\n",
      "Epoch 94/99[624/50000 (20%)]\tTrain Loss: 0.3938 Acc: 0.8632\tVal Loss: 0.8483 Acc: 0.7438\n",
      "Epoch 95/99[624/50000 (20%)]\tTrain Loss: 0.4103 Acc: 0.8553\tVal Loss: 0.8594 Acc: 0.7377\n",
      "Epoch 96/99[624/50000 (20%)]\tTrain Loss: 0.4274 Acc: 0.8497\tVal Loss: 0.8952 Acc: 0.7253\n",
      "Epoch 97/99[624/50000 (20%)]\tTrain Loss: 0.4433 Acc: 0.8426\tVal Loss: 0.8842 Acc: 0.7334\n",
      "Epoch 98/99[624/50000 (20%)]\tTrain Loss: 0.4488 Acc: 0.8400\tVal Loss: 0.8720 Acc: 0.7323\n",
      "Epoch 99/99[624/50000 (20%)]\tTrain Loss: 0.4524 Acc: 0.8388\tVal Loss: 0.9268 Acc: 0.7229\n",
      "\n",
      "Best val Acc: 0.748900\n",
      "\n",
      "Elapsed time - : 4min 29s\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"batch_size\": 512,\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 0.001,\n",
    "    \"momentum\": 0.9,\n",
    "}\n",
    "\n",
    "dataloaders = init_dataloaders(batch_size)\n",
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                                            lr=params[\"lr\"])\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer=optimizer,\n",
    "                                                                              T_max=10,  # Maximum number of iterations\n",
    "                                                                              eta_min=0,  # 最小学習率\n",
    "                                                                              last_epoch=-1)  # The index of last epoch\n",
    "\n",
    "model = train(model, criterion, optimizer, scheduler, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_acc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49[624/50000 (20%)]\tTrain Loss: 1.5811 Acc: 0.4110\tVal Loss: 1.3534 Acc: 0.5036\n",
      "Epoch 1/49[624/50000 (20%)]\tTrain Loss: 1.2127 Acc: 0.5637\tVal Loss: 1.1667 Acc: 0.5807\n",
      "Epoch 2/49[624/50000 (20%)]\tTrain Loss: 1.0894 Acc: 0.6124\tVal Loss: 1.0854 Acc: 0.6202\n",
      "Epoch 3/49[624/50000 (20%)]\tTrain Loss: 1.0249 Acc: 0.6376\tVal Loss: 1.0472 Acc: 0.6355\n",
      "Epoch 4/49[624/50000 (20%)]\tTrain Loss: 0.9751 Acc: 0.6580\tVal Loss: 0.9833 Acc: 0.6490\n",
      "Epoch 5/49[624/50000 (20%)]\tTrain Loss: 0.9337 Acc: 0.6704\tVal Loss: 0.9825 Acc: 0.6502\n",
      "Epoch 6/49[624/50000 (20%)]\tTrain Loss: 0.9030 Acc: 0.6838\tVal Loss: 0.9571 Acc: 0.6601\n",
      "Epoch 7/49[624/50000 (20%)]\tTrain Loss: 0.8847 Acc: 0.6883\tVal Loss: 0.9255 Acc: 0.6736\n",
      "Epoch 8/49[624/50000 (20%)]\tTrain Loss: 0.8571 Acc: 0.6982\tVal Loss: 0.9048 Acc: 0.6764\n",
      "Epoch 9/49[624/50000 (20%)]\tTrain Loss: 0.8268 Acc: 0.7060\tVal Loss: 0.9357 Acc: 0.6683\n",
      "Epoch 10/49[624/50000 (20%)]\tTrain Loss: 0.8092 Acc: 0.7144\tVal Loss: 0.8582 Acc: 0.6950\n",
      "Epoch 11/49[624/50000 (20%)]\tTrain Loss: 0.7917 Acc: 0.7218\tVal Loss: 0.9013 Acc: 0.6780\n",
      "Epoch 12/49[624/50000 (20%)]\tTrain Loss: 0.7759 Acc: 0.7274\tVal Loss: 0.8617 Acc: 0.6946\n",
      "Epoch 13/49[624/50000 (20%)]\tTrain Loss: 0.7605 Acc: 0.7312\tVal Loss: 0.8731 Acc: 0.6954\n",
      "Epoch 14/49[624/50000 (20%)]\tTrain Loss: 0.7455 Acc: 0.7390\tVal Loss: 0.8800 Acc: 0.6896\n",
      "Epoch 15/49[624/50000 (20%)]\tTrain Loss: 0.7348 Acc: 0.7422\tVal Loss: 0.8360 Acc: 0.7062\n",
      "Epoch 16/49[624/50000 (20%)]\tTrain Loss: 0.7215 Acc: 0.7467\tVal Loss: 0.8219 Acc: 0.7071\n",
      "Epoch 17/49[624/50000 (20%)]\tTrain Loss: 0.7108 Acc: 0.7506\tVal Loss: 0.8543 Acc: 0.7051\n",
      "Epoch 18/49[624/50000 (20%)]\tTrain Loss: 0.6942 Acc: 0.7571\tVal Loss: 0.8115 Acc: 0.7128\n",
      "Epoch 19/49[624/50000 (20%)]\tTrain Loss: 0.6840 Acc: 0.7604\tVal Loss: 0.8486 Acc: 0.7026\n",
      "Epoch 20/49[624/50000 (20%)]\tTrain Loss: 0.6677 Acc: 0.7656\tVal Loss: 0.8177 Acc: 0.7109\n",
      "Epoch 21/49[624/50000 (20%)]\tTrain Loss: 0.6618 Acc: 0.7676\tVal Loss: 0.8161 Acc: 0.7164\n",
      "Epoch 22/49[624/50000 (20%)]\tTrain Loss: 0.6481 Acc: 0.7728\tVal Loss: 0.8232 Acc: 0.7128\n",
      "Epoch 23/49[624/50000 (20%)]\tTrain Loss: 0.6411 Acc: 0.7753\tVal Loss: 0.8084 Acc: 0.7191\n",
      "Epoch 24/49[624/50000 (20%)]\tTrain Loss: 0.6359 Acc: 0.7781\tVal Loss: 0.8148 Acc: 0.7210\n",
      "Epoch 25/49[624/50000 (20%)]\tTrain Loss: 0.6255 Acc: 0.7813\tVal Loss: 0.8271 Acc: 0.7193\n",
      "Epoch 26/49[624/50000 (20%)]\tTrain Loss: 0.6188 Acc: 0.7835\tVal Loss: 0.8150 Acc: 0.7165\n",
      "Epoch 27/49[624/50000 (20%)]\tTrain Loss: 0.6046 Acc: 0.7889\tVal Loss: 0.7928 Acc: 0.7263\n",
      "Epoch 28/49[624/50000 (20%)]\tTrain Loss: 0.6016 Acc: 0.7892\tVal Loss: 0.8245 Acc: 0.7145\n",
      "Epoch 29/49[624/50000 (20%)]\tTrain Loss: 0.5955 Acc: 0.7918\tVal Loss: 0.8425 Acc: 0.7118\n",
      "Epoch 30/49[624/50000 (20%)]\tTrain Loss: 0.5909 Acc: 0.7923\tVal Loss: 0.8280 Acc: 0.7194\n",
      "Epoch 31/49[624/50000 (20%)]\tTrain Loss: 0.5789 Acc: 0.7968\tVal Loss: 0.8100 Acc: 0.7220\n",
      "Epoch 32/49[624/50000 (20%)]\tTrain Loss: 0.5735 Acc: 0.7970\tVal Loss: 0.7997 Acc: 0.7286\n",
      "Epoch 33/49[624/50000 (20%)]\tTrain Loss: 0.5673 Acc: 0.8005\tVal Loss: 0.8135 Acc: 0.7236\n",
      "Epoch 34/49[624/50000 (20%)]\tTrain Loss: 0.5564 Acc: 0.8043\tVal Loss: 0.8067 Acc: 0.7311\n",
      "Epoch 35/49[624/50000 (20%)]\tTrain Loss: 0.5526 Acc: 0.8058\tVal Loss: 0.8199 Acc: 0.7252\n",
      "Epoch 36/49[624/50000 (20%)]\tTrain Loss: 0.5448 Acc: 0.8112\tVal Loss: 0.8086 Acc: 0.7275\n",
      "Epoch 37/49[624/50000 (20%)]\tTrain Loss: 0.5418 Acc: 0.8106\tVal Loss: 0.8170 Acc: 0.7309\n",
      "Epoch 38/49[624/50000 (20%)]\tTrain Loss: 0.5351 Acc: 0.8130\tVal Loss: 0.8176 Acc: 0.7272\n",
      "Epoch 39/49[624/50000 (20%)]\tTrain Loss: 0.5307 Acc: 0.8117\tVal Loss: 0.8115 Acc: 0.7323\n",
      "Epoch 40/49[624/50000 (20%)]\tTrain Loss: 0.5186 Acc: 0.8173\tVal Loss: 0.8270 Acc: 0.7232\n",
      "Epoch 41/49[624/50000 (20%)]\tTrain Loss: 0.5117 Acc: 0.8208\tVal Loss: 0.8329 Acc: 0.7231\n",
      "Epoch 42/49[624/50000 (20%)]\tTrain Loss: 0.5071 Acc: 0.8228\tVal Loss: 0.8598 Acc: 0.7192\n",
      "Epoch 43/49[624/50000 (20%)]\tTrain Loss: 0.5018 Acc: 0.8240\tVal Loss: 0.8623 Acc: 0.7189\n",
      "Epoch 44/49[624/50000 (20%)]\tTrain Loss: 0.5073 Acc: 0.8208\tVal Loss: 0.8389 Acc: 0.7247\n",
      "Epoch 45/49[624/50000 (20%)]\tTrain Loss: 0.4928 Acc: 0.8260\tVal Loss: 0.8329 Acc: 0.7296\n",
      "Epoch 46/49[624/50000 (20%)]\tTrain Loss: 0.4916 Acc: 0.8274\tVal Loss: 0.8575 Acc: 0.7202\n",
      "Epoch 47/49[624/50000 (20%)]\tTrain Loss: 0.4882 Acc: 0.8275\tVal Loss: 0.8445 Acc: 0.7210\n",
      "Epoch 48/49[624/50000 (20%)]\tTrain Loss: 0.4798 Acc: 0.8303\tVal Loss: 0.8511 Acc: 0.7233\n",
      "Epoch 49/49[624/50000 (20%)]\tTrain Loss: 0.4831 Acc: 0.8301\tVal Loss: 0.8594 Acc: 0.7233\n",
      "\n",
      "Best val Acc: 0.732300\n",
      "\n",
      "Elapsed time - : 2min 17s\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"batch_size\": 1024,\n",
    "    \"epochs\": 50,\n",
    "    \"lr\": 0.001,\n",
    "    \"momentum\": 0.9,\n",
    "}\n",
    "\n",
    "dataloaders = init_dataloaders(batch_size)\n",
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                                            lr=params[\"lr\"])\n",
    "scheduler = lr_scheduler.StepLR(optimizer=optimizer,\n",
    "                                                     step_size=10,\n",
    "                                                     gamma=0.9)\n",
    "\n",
    "model = train(model, criterion, optimizer, scheduler, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of\tplane:\t77 %\n",
      "Accuracy of\t  car:\t83 %\n",
      "Accuracy of\t bird:\t58 %\n",
      "Accuracy of\t  cat:\t55 %\n",
      "Accuracy of\t deer:\t69 %\n",
      "Accuracy of\t  dog:\t65 %\n",
      "Accuracy of\t frog:\t80 %\n",
      "Accuracy of\thorse:\t79 %\n",
      "Accuracy of\t ship:\t87 %\n",
      "Accuracy of\ttruck:\t76 %\n"
     ]
    }
   ],
   "source": [
    "calc_acc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets, dataset_sizes = init_datasets(data_transforms)\n",
    "dataloaders = init_dataloaders(params[\"batch_size\"], image_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root=\"../../data\",\n",
    "                                                                       train=True,\n",
    "                                                                       download=True,\n",
    "                                                                       transform=transforms.Compose([\n",
    "                                                                           transforms.RandomResizedCrop(224),\n",
    "                                                                           transforms.RandomHorizontalFlip(),\n",
    "                                                                           transforms.ToTensor(),\n",
    "                                                                           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                                                       ]))\n",
    "dataloader[TRAIN] = torch.utils.data.DataLoader(trainset,\n",
    "                                                                           batch_size=batch_size,\n",
    "                                                                           shuffle=True,\n",
    "                                                                           num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=\"../../data\",\n",
    "                                                                      train=False,\n",
    "                                                                      download=True,\n",
    "                                                                       transform=transforms.Compose([\n",
    "                                                                           transforms.Resize(256),\n",
    "                                                                           transforms.RandomResizedCrop(224),\n",
    "                                                                           transforms.ToTensor(),\n",
    "                                                                           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                                                       ]))\n",
    "test_loader = torch.utils.data.DataLoader(testset,\n",
    "                                                                          batch_size=test_batch_size,\n",
    "                                                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 0/9\tTrain Loss: 1.7387 Acc: 0.3708\tVal Loss: 1.4421 Acc: 0.5036\n",
      "Epoch 1/9\tTrain Loss: 1.2732 Acc: 0.5488\tVal Loss: 1.1030 Acc: 0.6130\n",
      "Epoch 2/9\tTrain Loss: 1.0802 Acc: 0.6244\tVal Loss: 0.9498 Acc: 0.6655\n",
      "Epoch 3/9\tTrain Loss: 0.9553 Acc: 0.6687\tVal Loss: 0.9017 Acc: 0.6852\n",
      "Epoch 4/9\tTrain Loss: 0.8681 Acc: 0.6984\tVal Loss: 0.8207 Acc: 0.7140\n",
      "Epoch 5/9\tTrain Loss: 0.7906 Acc: 0.7255\tVal Loss: 0.7459 Acc: 0.7405\n",
      "Epoch 6/9\tTrain Loss: 0.7178 Acc: 0.7519\tVal Loss: 0.6653 Acc: 0.7708\n",
      "Epoch 7/9\tTrain Loss: 0.6653 Acc: 0.7705\tVal Loss: 0.6405 Acc: 0.7803\n",
      "Epoch 8/9\tTrain Loss: 0.6177 Acc: 0.7858\tVal Loss: 0.6066 Acc: 0.7914\n",
      "Epoch 9/9\tTrain Loss: 0.5945 Acc: 0.7938\tVal Loss: 0.6058 Acc: 0.7930\n",
      "\n",
      "Best val Acc: 0.793000\n",
      "\n",
      "Elapsed time - : 26min 57s\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 10,\n",
    "    \"lr\": 0.001,\n",
    "    \"momentum\": 0.9,\n",
    "}\n",
    "\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets, dataset_sizes = init_datasets(data_transforms)\n",
    "dataloaders = init_dataloaders(params[\"batch_size\"], image_datasets)\n",
    "\n",
    "# Load pretrained model\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.conv1 = nn.Conv2d(in_channels=3,\n",
    "                                                    out_channels=64,\n",
    "                                                    kernel_size=7,\n",
    "                                                    stride=2,\n",
    "                                                    padding=3,\n",
    "                                                    bias=False)\n",
    "model_ft.fc = nn.Linear(num_ftrs, 10)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_ft.parameters(),\n",
    "                                            lr=params[\"lr\"])\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer=optimizer,\n",
    "                                                                              T_max=10,  # Maximum number of iterations\n",
    "                                                                              eta_min=0,  # 最小学習率\n",
    "                                                                              last_epoch=-1)  # The index of last epoch\n",
    "\n",
    "model_ft = train(model_ft, criterion, optimizer, scheduler, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-027880b9929a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msince\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for (inputs, labels) in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(\"Accuracy of the network on the 10000 test images: %d %%\" % (100 * correct / total))\n",
    "\n",
    "display_formatted_time(time.time() - since)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.conv1 = nn.Conv2d(in_channels=3,\n",
    "                                                    out_channels=64,\n",
    "                                                    kernel_size=7,\n",
    "                                                    stride=2,\n",
    "                                                    padding=3,\n",
    "                                                    bias=False)\n",
    "model_ft.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "print(model_ft)\n",
    "\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(),\n",
    "                                              lr=lr,\n",
    "                                              momentum=momentum)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloader[TRAIN], 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model_ft(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        exp_lr_scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % log_interval == (log_interval - 1):\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tRunningLoss: {:.3f}\".format(\n",
    "                epoch, batch_idx * len(inputs), len(dataloader[TRAIN].dataset),\n",
    "                100. * batch_idx / len(dataloader[TRAIN]), loss.item(), running_loss / log_interval\n",
    "            ))\n",
    "            running_loss = 0.0\n",
    "\n",
    "display_formatted_time(time.time() - since)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 8 %\n",
      "Elapsed time - : 0min 26s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for (inputs, labels) in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(\"Accuracy of the network on the 10000 test images: %d %%\" % (100 * correct / total))\n",
    "\n",
    "display_formatted_time(time.time() - since)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.vgg16(pretrained=True)\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model_ft.classifier[6].in_features\n",
    "\n",
    "model_ft.classifier[6] = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "print(model_ft)\n",
    "\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(),\n",
    "                                              lr=lr,\n",
    "                                              momentum=momentum)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [7996/50000 (16%)]\tLoss: 2.159346\tRunningLoss: 2.387\n",
      "Train Epoch: 0 [15996/50000 (32%)]\tLoss: 2.379969\tRunningLoss: 2.390\n",
      "Train Epoch: 0 [23996/50000 (48%)]\tLoss: 2.332590\tRunningLoss: 2.394\n",
      "Train Epoch: 0 [31996/50000 (64%)]\tLoss: 2.595869\tRunningLoss: 2.391\n",
      "Train Epoch: 0 [39996/50000 (80%)]\tLoss: 2.534103\tRunningLoss: 2.386\n",
      "Train Epoch: 0 [47996/50000 (96%)]\tLoss: 2.623924\tRunningLoss: 2.388\n",
      "Train Epoch: 1 [7996/50000 (16%)]\tLoss: 2.777625\tRunningLoss: 2.381\n",
      "Train Epoch: 1 [15996/50000 (32%)]\tLoss: 2.251991\tRunningLoss: 2.390\n",
      "Train Epoch: 1 [23996/50000 (48%)]\tLoss: 2.551284\tRunningLoss: 2.396\n",
      "Train Epoch: 1 [31996/50000 (64%)]\tLoss: 2.533488\tRunningLoss: 2.397\n",
      "Train Epoch: 1 [39996/50000 (80%)]\tLoss: 2.538293\tRunningLoss: 2.386\n",
      "Train Epoch: 1 [47996/50000 (96%)]\tLoss: 2.136362\tRunningLoss: 2.382\n",
      "Elapsed time - : 11min 39s\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloader[TRAIN], 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model_ft(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        exp_lr_scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % log_interval == (log_interval - 1):\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tRunningLoss: {:.3f}\".format(\n",
    "                epoch, batch_idx * len(inputs), len(dataloader[TRAIN].dataset),\n",
    "                100. * batch_idx / len(dataloader[TRAIN]), loss.item(), running_loss / log_interval\n",
    "            ))\n",
    "            running_loss = 0.0\n",
    "\n",
    "display_formatted_time(time.time() - since)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_ft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-027880b9929a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_ft' is not defined"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for (inputs, labels) in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print(\"Accuracy of the network on the 10000 test images: %d %%\" % (100 * correct / total))\n",
    "\n",
    "display_formatted_time(time.time() - since)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 7, 1, 9], device='cuda:0')\n",
      "tensor([[-0.0806, -0.0588, -0.0060, -0.0684,  0.5789, -0.2355,  0.0837,  0.1491,\n",
      "          0.3314,  0.1944],\n",
      "        [ 0.1758, -0.4445,  0.3566,  0.0683,  0.2534,  0.4132, -0.0509,  0.3535,\n",
      "          0.0414, -0.1509],\n",
      "        [-0.3567, -0.2181, -0.7075,  0.2487, -0.4086, -0.2820,  0.2147, -0.0063,\n",
      "          0.1472,  0.0601],\n",
      "        [ 0.3038, -0.3477, -0.2707,  0.1142,  0.3598,  0.2226, -0.0590,  0.2238,\n",
      "          0.0006, -0.0278]], device='cuda:0', grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
